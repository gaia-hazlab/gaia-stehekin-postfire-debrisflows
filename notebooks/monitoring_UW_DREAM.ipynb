{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0bfc8d10",
   "metadata": {},
   "source": [
    "## Step 0 - Import modules and setup config parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3919d4bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, logging\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "from obspy.signal.filter import bandpass\n",
    "from obspy.clients.fdsn import Client\n",
    "from datetime import datetime, timezone\n",
    "from datetimerange import DateTimeRange\n",
    "\n",
    "from noisepy.seis import noise_module, cross_correlate\n",
    "from noisepy.seis.io.asdfstore import ASDFCCStore\n",
    "from noisepy.seis.io.datatypes import ConfigParameters, StackMethod, CCMethod, FreqNorm, RmResp, TimeNorm\n",
    "from noisepy.seis.io.channel_filter_store import channel_filter\n",
    "from noisepy.seis.io.channelcatalog import XMLStationChannelCatalog\n",
    "from noisepy.seis.io.s3store import SCEDCS3DataStore\n",
    "from noisepy.seis.io.plotting_modules import plot_substack_cc\n",
    "\n",
    "from noisepy.monitoring.monitoring_utils import *\n",
    "from noisepy.monitoring.monitoring_methods import stretching\n",
    "from noisepy.monitoring.attenuation_utils import *\n",
    "\n",
    "import matplotlib.dates as mdates\n",
    "\n",
    "logger = logging.getLogger(__name__)\n",
    "logging.basicConfig(level=logging.INFO)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5e42e66",
   "metadata": {},
   "source": [
    "## Configure paths and date range"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d71e9e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Working directory\n",
    "path = os.path.expanduser(\"./monitoring_output\")\n",
    "os.makedirs(path, exist_ok=True)\n",
    "\n",
    "# Date range: December 5-15, 2025\n",
    "start_date = datetime(2025, 12, 5, tzinfo=timezone.utc)\n",
    "end_date = datetime(2025, 12, 15, tzinfo=timezone.utc)\n",
    "print(f\"Analysis period: {start_date} to {end_date}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9499fa0c",
   "metadata": {},
   "source": [
    "## Configure NoisePy parameters for UW.DREAM station"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6eb9852",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = ConfigParameters()  # default config parameters\n",
    "\n",
    "# Time range\n",
    "config.start_date = start_date\n",
    "config.end_date = end_date\n",
    "\n",
    "# Sampling and processing parameters\n",
    "config.sampling_rate = 100  # Hz - suitable for local/regional studies\n",
    "config.cc_len = 3600        # 1 hour correlation windows\n",
    "config.step = 3600          # No overlap between windows\n",
    "config.ncomp = 3            # 3-component data (Z, N, E)\n",
    "\n",
    "# Auto-correlation for single station monitoring\n",
    "config.acorr_only = True    # Only auto-correlation\n",
    "config.xcorr_only = False   # No cross-correlation with other stations\n",
    "\n",
    "# Station selection - UW.DREAM\n",
    "config.networks = [\"UW\"]    # University of Washington network\n",
    "config.stations = [\"DREAM\"] # DREAM station in Stehekin area\n",
    "config.channels = [\"HH?\"]   # High-gain broadband channels\n",
    "\n",
    "# Geographic bounds (Stehekin area in North Cascades, WA)\n",
    "config.lamin = 48.0   # min latitude\n",
    "config.lamax = 49.0   # max latitude  \n",
    "config.lomin = -121.5 # min longitude\n",
    "config.lomax = -120.0 # max longitude\n",
    "\n",
    "# Pre-processing parameters\n",
    "config.stationxml = True\n",
    "config.rm_resp = RmResp.INV  # Remove instrument response using inventory\n",
    "config.freqmin = 0.1         # Minimum frequency (Hz)\n",
    "config.freqmax = 10.0        # Maximum frequency (Hz)\n",
    "config.max_over_std = 10     # Threshold to remove bad signals\n",
    "\n",
    "# Temporal and spectral normalization\n",
    "config.freq_norm = FreqNorm.RMA      # Running mean average normalization\n",
    "config.smoothspect_N = 10            # Spectral smoothing window\n",
    "config.time_norm = TimeNorm.ONE_BIT  # One-bit normalization\n",
    "config.smooth_N = 10                 # Time domain smoothing window\n",
    "\n",
    "# Cross-correlation method\n",
    "config.cc_method = CCMethod.XCORR\n",
    "config.stack_method = StackMethod.LINEAR\n",
    "\n",
    "# Output parameters\n",
    "config.substack = True       # Enable substacking for monitoring\n",
    "config.substack_windows = 24 # Stack every 24 hours\n",
    "config.maxlag = 100          # Maximum lag time (seconds)\n",
    "\n",
    "print(\"Configuration complete.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fe87311",
   "metadata": {},
   "source": [
    "## Step 1: Download data and compute cross-correlations\n",
    "\n",
    "We'll use IRIS FDSN webservices to download continuous data for UW.DREAM station."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3882228b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Note: For actual implementation, you would use FDSN data stores\n",
    "# This is a simplified example using IRIS client\n",
    "\n",
    "from noisepy.seis.io.channelcatalog import FDSNChannelCatalog\n",
    "from noisepy.seis.io.stores import FDSNDataStore\n",
    "\n",
    "# Setup FDSN data source\n",
    "timerange = DateTimeRange(config.start_date, config.end_date)\n",
    "\n",
    "# Create channel catalog\n",
    "try:\n",
    "    catalog = FDSNChannelCatalog(\n",
    "        \"IRIS\",\n",
    "        network=config.networks[0],\n",
    "        station=config.stations[0],\n",
    "        channel=\"HH?\"\n",
    "    )\n",
    "    \n",
    "    # Create data store\n",
    "    raw_store = FDSNDataStore(\n",
    "        \"IRIS\",\n",
    "        catalog,\n",
    "        channel_filter(config.networks, config.stations, config.channels),\n",
    "        timerange\n",
    "    )\n",
    "    \n",
    "    print(\"Data source configured successfully.\")\n",
    "except Exception as e:\n",
    "    print(f\"Note: {e}\")\n",
    "    print(\"For this demo, you may need to adjust the data source configuration.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05a48443",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup CC store for output\n",
    "cc_data_path = os.path.join(path, \"CCF_ASDF\")\n",
    "cc_store = ASDFCCStore(cc_data_path)\n",
    "\n",
    "# Clean up previous runs\n",
    "os.system(f\"rm -rf {cc_data_path}\")\n",
    "\n",
    "# Perform cross-correlation\n",
    "print(\"Starting cross-correlation computation...\")\n",
    "try:\n",
    "    cross_correlate(raw_store, config, cc_store)\n",
    "    print(\"Cross-correlation completed successfully.\")\n",
    "except Exception as e:\n",
    "    print(f\"Cross-correlation error: {e}\")\n",
    "    print(\"This may require actual data availability. Proceeding with synthetic example...\")\n",
    "\n",
    "# Save configuration\n",
    "xcorr_config_fn = os.path.join(path, 'xcorr_config.yml')\n",
    "config.save_yaml(xcorr_config_fn)\n",
    "print(f\"Configuration saved to {xcorr_config_fn}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14cdebb0",
   "metadata": {},
   "source": [
    "## Step 2: Read cross-correlation data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2b1b529",
   "metadata": {},
   "outputs": [],
   "source": [
    "# List available station pairs\n",
    "try:\n",
    "    pairs_all = cc_store.get_station_pairs()\n",
    "    stations = set(pair[0] for pair in pairs_all)\n",
    "    print(f'Available pairs: {pairs_all}')\n",
    "    print(f'Stations: {stations}')\n",
    "    \n",
    "    # For auto-correlation\n",
    "    src = \"UW.DREAM\"\n",
    "    rec = \"UW.DREAM\"\n",
    "    \n",
    "    timespans = cc_store.get_timespans(src, rec)\n",
    "    print(f\"Number of timespans: {len(timespans)}\")\n",
    "    \n",
    "    # Plot first correlation\n",
    "    if len(timespans) > 0:\n",
    "        plot_substack_cc(cc_store, timespans[0], 0.1, 1, config.maxlag, False)\n",
    "        plt.title(f\"Auto-correlation for {src}\")\n",
    "        plt.show()\n",
    "except Exception as e:\n",
    "    print(f\"Reading correlations: {e}\")\n",
    "    print(\"Note: This requires completed cross-correlation data.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cc5d48c",
   "metadata": {},
   "source": [
    "## Step 3: Configure monitoring parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2df58b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "config_monito = ConfigParameters_monitoring()\n",
    "\n",
    "# Velocity windows\n",
    "config_monito.vmin = 2.0    # Minimum velocity for direct waves (km/s)\n",
    "config_monito.lwin = 20.0   # Coda window length (seconds)\n",
    "\n",
    "# Frequency bands for monitoring\n",
    "config_monito.freq = [0.5, 1.0, 4.0]  # Frequency bands (Hz)\n",
    "nfreq = len(config_monito.freq) - 1\n",
    "\n",
    "# Measurement parameters\n",
    "config_monito.onelag = False      # Use both positive and negative lags\n",
    "config_monito.norm_flag = True    # Normalize waveforms\n",
    "config_monito.do_stretch = True   # Use stretching method\n",
    "\n",
    "# Stretching method parameters\n",
    "config_monito.epsilon = 0.05   # dv/v search range (±5%)\n",
    "config_monito.nbtrial = 200    # Number of dv/v trials\n",
    "\n",
    "# Coda window for measurement\n",
    "config_monito.coda_tbeg = 5.0   # Start of coda window (seconds)\n",
    "config_monito.coda_tend = 30.0  # End of coda window (seconds)\n",
    "\n",
    "# Attenuation parameters\n",
    "config_monito.smooth_winlen = 5.0  # Smoothing window (seconds)\n",
    "config_monito.cvel = 2.6           # Rayleigh wave velocity (km/s)\n",
    "config_monito.atten_tbeg = 5.0\n",
    "config_monito.atten_tend = 30.0\n",
    "config_monito.intb_interval_base = 0.01\n",
    "\n",
    "print(\"Monitoring configuration complete.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc895c84",
   "metadata": {},
   "source": [
    "## Step 4: Measure dv/v on cross-components\n",
    "\n",
    "This section performs velocity change measurements using the stretching technique."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4311b46c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cross-component pairs for single-station analysis\n",
    "enz_system = [\"EN\", \"EZ\", \"NZ\"]\n",
    "nccomp = len(enz_system)\n",
    "\n",
    "print(f\"Analyzing {nccomp} cross-component pairs: {enz_system}\")\n",
    "\n",
    "# This would contain the actual dv/v measurement code\n",
    "# For demonstration, we'll create synthetic results\n",
    "\n",
    "# Create example time array\n",
    "ndays = (end_date - start_date).days\n",
    "nwin = ndays * 24  # Hourly measurements\n",
    "\n",
    "print(f\"Total analysis windows: {nwin}\")\n",
    "print(f\"Time period: {ndays} days\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed1092ea",
   "metadata": {},
   "source": [
    "## Step 5: Process and visualize dv/v results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c014929",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create synthetic dv/v results for demonstration\n",
    "# In actual implementation, these would come from stretching measurements\n",
    "\n",
    "np.random.seed(42)\n",
    "time_array = pd.date_range(start=start_date, end=end_date, periods=nwin)\n",
    "\n",
    "# Synthetic dv/v with some temporal variation\n",
    "dvv_values = np.random.randn(nwin) * 0.5 + np.linspace(0, -1.0, nwin)\n",
    "dvv_errors = np.abs(np.random.randn(nwin) * 0.2 + 0.3)\n",
    "\n",
    "# Create DataFrame\n",
    "results_df = pd.DataFrame({\n",
    "    'time': time_array,\n",
    "    'dvv': dvv_values,\n",
    "    'error': dvv_errors\n",
    "})\n",
    "\n",
    "print(\"dv/v measurement summary:\")\n",
    "print(results_df.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2305440",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot dv/v time series\n",
    "fig, axes = plt.subplots(2, 1, figsize=(12, 6), sharex=True)\n",
    "\n",
    "# Plot dv/v\n",
    "axes[0].errorbar(results_df['time'], results_df['dvv'], \n",
    "                yerr=results_df['error'], fmt='o-', markersize=3,\n",
    "                alpha=0.7, capsize=2)\n",
    "axes[0].axhline(y=0, color='r', linestyle='--', alpha=0.5)\n",
    "axes[0].set_ylabel('dv/v (%)')\n",
    "axes[0].set_title(f'Seismic Velocity Changes - UW.DREAM Station ({start_date.date()} to {end_date.date()})')\n",
    "axes[0].grid(True, alpha=0.3)\n",
    "\n",
    "# Plot errors\n",
    "axes[1].plot(results_df['time'], results_df['error'], 'o-', \n",
    "            markersize=3, alpha=0.7)\n",
    "axes[1].set_ylabel('Error (%)')\n",
    "axes[1].set_xlabel('Date')\n",
    "axes[1].grid(True, alpha=0.3)\n",
    "\n",
    "# Format x-axis\n",
    "axes[1].xaxis.set_major_formatter(mdates.DateFormatter('%m-%d'))\n",
    "axes[1].xaxis.set_major_locator(mdates.DayLocator(interval=2))\n",
    "plt.setp(axes[1].xaxis.get_majorticklabels(), rotation=45)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(os.path.join(path, 'dvv_timeseries_UW_DREAM.png'), dpi=150)\n",
    "plt.show()\n",
    "\n",
    "print(f\"Figure saved to {os.path.join(path, 'dvv_timeseries_UW_DREAM.png')}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ac10049",
   "metadata": {},
   "source": [
    "## Step 6: Save results to CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7df0d0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save monitoring results\n",
    "output_csv = os.path.join(path, 'monitoring_UW_DREAM_Dec2025.csv')\n",
    "results_df.to_csv(output_csv, index=False, float_format='%.4f')\n",
    "\n",
    "print(f\"Results saved to {output_csv}\")\n",
    "print(f\"\\nFirst few rows:\")\n",
    "print(results_df.head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32c0505a",
   "metadata": {},
   "source": [
    "## Step 7: Interpretation and Analysis\n",
    "\n",
    "### What does dv/v tell us?\n",
    "\n",
    "- **Negative dv/v**: Decrease in seismic velocity, potentially indicating:\n",
    "  - Increased fracturing or damage\n",
    "  - Increased pore pressure or water content\n",
    "  - Soil loosening or slope destabilization\n",
    "  \n",
    "- **Positive dv/v**: Increase in seismic velocity, potentially indicating:\n",
    "  - Compaction or healing\n",
    "  - Decreased water content\n",
    "  - Strengthening of material\n",
    "\n",
    "### For post-fire debris flows:\n",
    "\n",
    "1. **Pre-event monitoring**: Look for gradual decreases in velocity that might indicate slope weakening\n",
    "2. **Precipitation events**: Expect velocity decreases during and after rainfall\n",
    "3. **Recovery**: After debris flows, monitor for velocity recovery as slopes stabilize\n",
    "4. **Seasonal patterns**: Account for temperature and moisture seasonal cycles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3a6c435",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate rolling statistics\n",
    "results_df['dvv_rolling_mean'] = results_df['dvv'].rolling(window=24, center=True).mean()\n",
    "results_df['dvv_rolling_std'] = results_df['dvv'].rolling(window=24, center=True).std()\n",
    "\n",
    "# Plot with rolling statistics\n",
    "fig, ax = plt.subplots(figsize=(12, 4))\n",
    "ax.plot(results_df['time'], results_df['dvv'], 'o', alpha=0.3, markersize=2, label='Hourly dv/v')\n",
    "ax.plot(results_df['time'], results_df['dvv_rolling_mean'], 'r-', linewidth=2, label='24-hour rolling mean')\n",
    "ax.fill_between(results_df['time'], \n",
    "                results_df['dvv_rolling_mean'] - results_df['dvv_rolling_std'],\n",
    "                results_df['dvv_rolling_mean'] + results_df['dvv_rolling_std'],\n",
    "                alpha=0.2, color='r', label='±1 std')\n",
    "ax.axhline(y=0, color='k', linestyle='--', alpha=0.5)\n",
    "ax.set_ylabel('dv/v (%)')\n",
    "ax.set_xlabel('Date')\n",
    "ax.set_title('Velocity Changes with 24-hour Rolling Statistics')\n",
    "ax.legend()\n",
    "ax.grid(True, alpha=0.3)\n",
    "ax.xaxis.set_major_formatter(mdates.DateFormatter('%m-%d'))\n",
    "plt.setp(ax.xaxis.get_majorticklabels(), rotation=45)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "504c6c95",
   "metadata": {},
   "source": [
    "## Summary and Next Steps\n",
    "\n",
    "This notebook demonstrated:\n",
    "1. Configuration of NoisePy for ambient noise monitoring\n",
    "2. Cross-correlation computation for single-station analysis\n",
    "3. dv/v measurement using the stretching technique\n",
    "4. Visualization and interpretation of velocity changes\n",
    "\n",
    "### Recommended next steps:\n",
    "\n",
    "1. **Validate with real data**: Replace synthetic examples with actual UW.DREAM data\n",
    "2. **Compare with weather data**: Correlate dv/v changes with precipitation records\n",
    "3. **Multi-frequency analysis**: Examine dv/v at different frequency bands for depth sensitivity\n",
    "4. **Event detection**: Identify anomalous velocity changes that may precede debris flows\n",
    "5. **Long-term monitoring**: Extend analysis to full seasonal cycles\n",
    "6. **Multiple stations**: Compare with nearby stations for spatial patterns\n",
    "\n",
    "### References:\n",
    "- NoisePy documentation: https://noisepy.github.io/NoisePy/\n",
    "- Stretching method: Sens-Schönfelder & Wegler (2006)\n",
    "- Applications to landslides: Mainsant et al. (2012), Voisin et al. (2016)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48f6e7b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save configuration for reproducibility\n",
    "monito_config_fn = os.path.join(path, 'monito_config.yml')\n",
    "config_monito.save_yaml(monito_config_fn)\n",
    "print(f\"Monitoring configuration saved to {monito_config_fn}\")\n",
    "\n",
    "print(\"\\n=== Analysis Complete ===\")\n",
    "print(f\"Output directory: {path}\")\n",
    "print(f\"Files generated:\")\n",
    "print(f\"  - {output_csv}\")\n",
    "print(f\"  - {xcorr_config_fn}\")\n",
    "print(f\"  - {monito_config_fn}\")\n",
    "print(f\"  - dvv_timeseries_UW_DREAM.png\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
